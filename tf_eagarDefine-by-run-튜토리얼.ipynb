{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Eager Tutorial (Define by Run)\n",
    "\n",
    "정리 및 요약 by Ryah Shin\n",
    "\n",
    "[참고1: 구글 블로그](https://research.googleblog.com/2017/10/eager-execution-imperative-define-by.html)\n",
    "\n",
    "[참고2: 구글 깃허브](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/g3doc/guide.md)\n",
    "\n",
    "[Eager 모드 설치방법(TF Nightly)](https://github.com/tensorflow/tensorflow#installation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'dragon4_positional'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-41389fad42b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpackages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madd_newdocs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     __all__ = ['add_newdocs',\n\u001b[0;32m    144\u001b[0m                \u001b[1;34m'ModuleDeprecationWarning'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\add_newdocs.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madd_newdoc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m###############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtype_check\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mindex_tricks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfunction_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\type_check.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m            'common_type']\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumeric\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumeric\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misnan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mufunclike\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0misneginf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misposinf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumerictypes\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_typeDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msctypeDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumeric\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnumeric\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfromnumeric\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1819\u001b[0m \u001b[1;31m# Use numarray's printing function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1820\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0marrayprint\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray2string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_printoptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_printoptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mumath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnot_equal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misnan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misinf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misfinite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misnat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m from .multiarray import (array, dragon4_positional, dragon4_scientific,\n\u001b[0m\u001b[0;32m     45\u001b[0m                          \u001b[0mdatetime_as_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatetime_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                          set_legacy_print_mode)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'dragon4_positional'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tf-nightly in /Users/dahlmoon/anaconda/lib/python3.6/site-packages\n",
      "Requirement already up-to-date: absl-py in /Users/dahlmoon/anaconda/lib/python3.6/site-packages (from tf-nightly)\n",
      "Requirement already up-to-date: enum34>=1.1.6 in /Users/dahlmoon/anaconda/lib/python3.6/site-packages (from tf-nightly)\n",
      "Requirement already up-to-date: six>=1.10.0 in /Users/dahlmoon/anaconda/lib/python3.6/site-packages (from tf-nightly)\n",
      "Requirement already up-to-date: protobuf>=3.4.0 in /Users/dahlmoon/anaconda/lib/python3.6/site-packages (from tf-nightly)\n",
      "Requirement already up-to-date: numpy>=1.12.1 in /Users/dahlmoon/anaconda/lib/python3.6/site-packages (from tf-nightly)\n",
      "Requirement already up-to-date: wheel>=0.26 in /Users/dahlmoon/anaconda/lib/python3.6/site-packages (from tf-nightly)\n",
      "Requirement already up-to-date: setuptools in /Users/dahlmoon/anaconda/lib/python3.6/site-packages (from protobuf>=3.4.0->tf-nightly)\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-nightly --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Usage:   \r\n",
      "  pip <command> [options]\r\n",
      "\r\n",
      "Commands:\r\n",
      "  install                     Install packages.\r\n",
      "  download                    Download packages.\r\n",
      "  uninstall                   Uninstall packages.\r\n",
      "  freeze                      Output installed packages in requirements format.\r\n",
      "  list                        List installed packages.\r\n",
      "  show                        Show information about installed packages.\r\n",
      "  check                       Verify installed packages have compatible dependencies.\r\n",
      "  search                      Search PyPI for packages.\r\n",
      "  wheel                       Build wheels from your requirements.\r\n",
      "  hash                        Compute hashes of package archives.\r\n",
      "  completion                  A helper command used for command completion.\r\n",
      "  help                        Show help for commands.\r\n",
      "\r\n",
      "General Options:\r\n",
      "  -h, --help                  Show help.\r\n",
      "  --isolated                  Run pip in an isolated mode, ignoring\r\n",
      "                              environment variables and user configuration.\r\n",
      "  -v, --verbose               Give more output. Option is additive, and can be\r\n",
      "                              used up to 3 times.\r\n",
      "  -V, --version               Show version and exit.\r\n",
      "  -q, --quiet                 Give less output. Option is additive, and can be\r\n",
      "                              used up to 3 times (corresponding to WARNING,\r\n",
      "                              ERROR, and CRITICAL logging levels).\r\n",
      "  --log <path>                Path to a verbose appending log.\r\n",
      "  --proxy <proxy>             Specify a proxy in the form\r\n",
      "                              [user:passwd@]proxy.server:port.\r\n",
      "  --retries <retries>         Maximum number of retries each connection should\r\n",
      "                              attempt (default 5 times).\r\n",
      "  --timeout <sec>             Set the socket timeout (default 15 seconds).\r\n",
      "  --exists-action <action>    Default action when a path already exists:\r\n",
      "                              (s)witch, (i)gnore, (w)ipe, (b)ackup, (a)bort.\r\n",
      "  --trusted-host <hostname>   Mark this host as trusted, even though it does\r\n",
      "                              not have valid or any HTTPS.\r\n",
      "  --cert <path>               Path to alternate CA bundle.\r\n",
      "  --client-cert <path>        Path to SSL client certificate, a single file\r\n",
      "                              containing the private key and the certificate\r\n",
      "                              in PEM format.\r\n",
      "  --cache-dir <dir>           Store the cache data in <dir>.\r\n",
      "  --no-cache-dir              Disable the cache.\r\n",
      "  --disable-pip-version-check\r\n",
      "                              Don't periodically check PyPI to determine\r\n",
      "                              whether a new version of pip is available for\r\n",
      "                              download. Implied with --no-index.\r\n"
     ]
    }
   ],
   "source": [
    "!pip help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.\u001b[0m\n",
      "absl-py (0.1.5)\n",
      "alabaster (0.7.10)\n",
      "anaconda-client (1.6.3)\n",
      "anaconda-navigator (1.6.2)\n",
      "anaconda-project (0.6.0)\n",
      "appnope (0.1.0)\n",
      "appscript (1.0.1)\n",
      "asn1crypto (0.22.0)\n",
      "astroid (1.4.9)\n",
      "astropy (1.3.2)\n",
      "Babel (2.4.0)\n",
      "backports.shutil-get-terminal-size (1.0.0)\n",
      "backports.tempfile (1.0)\n",
      "backports.weakref (1.0.post1)\n",
      "beautifulsoup4 (4.6.0)\n",
      "bitarray (0.8.1)\n",
      "blaze (0.10.1)\n",
      "bleach (1.5.0)\n",
      "bokeh (0.12.5)\n",
      "boto (2.48.0)\n",
      "Bottleneck (1.2.1)\n",
      "bz2file (0.98)\n",
      "certifi (2017.11.5)\n",
      "cffi (1.10.0)\n",
      "chardet (3.0.4)\n",
      "click (6.7)\n",
      "cloudpickle (0.2.2)\n",
      "clyent (1.2.2)\n",
      "colorama (0.3.9)\n",
      "conda (4.3.21)\n",
      "contextlib2 (0.5.5)\n",
      "cryptography (1.8.1)\n",
      "cycler (0.10.0)\n",
      "cymem (1.31.2)\n",
      "Cython (0.25.2)\n",
      "cytoolz (0.8.2)\n",
      "dask (0.14.3)\n",
      "datashape (0.5.4)\n",
      "decorator (4.1.2)\n",
      "dill (0.2.7.1)\n",
      "distributed (1.16.3)\n",
      "Django (1.11.4)\n",
      "docutils (0.13.1)\n",
      "en-core-web-sm (1.2.0)\n",
      "entrypoints (0.2.2)\n",
      "enum34 (1.1.6)\n",
      "et-xmlfile (1.0.1)\n",
      "fastcache (1.0.2)\n",
      "Flask (0.12.2)\n",
      "Flask-Cors (3.0.2)\n",
      "ftfy (4.4.3)\n",
      "gensim (2.3.0)\n",
      "gevent (1.2.1)\n",
      "graphviz (0.8)\n",
      "greenlet (0.4.12)\n",
      "h5py (2.7.0)\n",
      "HeapDict (1.0.0)\n",
      "html5lib (0.9999999)\n",
      "idna (2.6)\n",
      "image (1.5.12)\n",
      "imagesize (0.7.1)\n",
      "ipykernel (4.6.1)\n",
      "ipython (6.2.1)\n",
      "ipython-genutils (0.2.0)\n",
      "ipywidgets (6.0.0)\n",
      "isort (4.2.5)\n",
      "itsdangerous (0.24)\n",
      "jdcal (1.3)\n",
      "jedi (0.11.0)\n",
      "Jinja2 (2.9.6)\n",
      "JPype1-py3 (0.5.5.2)\n",
      "jsonschema (2.6.0)\n",
      "jupyter (1.0.0)\n",
      "jupyter-client (5.1.0)\n",
      "jupyter-console (5.1.0)\n",
      "jupyter-core (4.3.0)\n",
      "Keras (2.0.8)\n",
      "konlpy (0.4.4)\n",
      "lazy-object-proxy (1.2.2)\n",
      "llvmlite (0.18.0)\n",
      "locket (0.2.0)\n",
      "lxml (3.7.3)\n",
      "Markdown (2.6.9)\n",
      "MarkupSafe (0.23)\n",
      "matlab (0.1)\n",
      "matlab-kernel (0.14.3)\n",
      "matplotlib (2.1.0)\n",
      "matplotlib-venn (0.11.5)\n",
      "mecab-python3 (0.7)\n",
      "metakernel (0.20.7)\n",
      "mglearn (0.1.6)\n",
      "mistune (0.7.4)\n",
      "mpmath (0.19)\n",
      "msgpack-python (0.4.8)\n",
      "multipledispatch (0.4.9)\n",
      "murmurhash (0.26.4)\n",
      "mypy-lang (0.4.6)\n",
      "navigator-updater (0.1.0)\n",
      "nbconvert (5.1.1)\n",
      "nbformat (4.3.0)\n",
      "networkx (1.11)\n",
      "nltk (3.2.4)\n",
      "nose (1.3.7)\n",
      "notebook (5.0.0)\n",
      "numba (0.33.0)\n",
      "numexpr (2.6.2)\n",
      "numpy (1.13.3)\n",
      "numpydoc (0.6.0)\n",
      "oauthlib (2.0.2)\n",
      "odo (0.5.0)\n",
      "olefile (0.44)\n",
      "opencv-python (3.2.0.7)\n",
      "openpyxl (2.4.7)\n",
      "OSlash (0.5.1)\n",
      "overload (1.1)\n",
      "packaging (16.8)\n",
      "pandas (0.21.0)\n",
      "pandas-datareader (0.5.0)\n",
      "pandocfilters (1.4.1)\n",
      "parso (0.1.0)\n",
      "partd (0.3.8)\n",
      "pathlib (1.0.1)\n",
      "pathlib2 (2.2.1)\n",
      "patsy (0.4.1)\n",
      "pep8 (1.7.0)\n",
      "pexpect (4.2.1)\n",
      "pickleshare (0.7.4)\n",
      "Pillow (4.3.0)\n",
      "pip (9.0.1)\n",
      "plac (0.9.6)\n",
      "ply (3.10)\n",
      "preshed (1.0.0)\n",
      "prompt-toolkit (1.0.15)\n",
      "protobuf (3.5.0.post1)\n",
      "psutil (5.2.2)\n",
      "ptyprocess (0.5.1)\n",
      "py (1.4.33)\n",
      "pycosat (0.6.2)\n",
      "pycparser (2.17)\n",
      "pycrypto (2.6.1)\n",
      "pycurl (7.43.0)\n",
      "pyflakes (1.5.0)\n",
      "Pygments (2.2.0)\n",
      "pylint (1.6.4)\n",
      "pymatbridge (0.5.2)\n",
      "pymatlab (0.2.3)\n",
      "pyodbc (4.0.16)\n",
      "pyOpenSSL (17.0.0)\n",
      "pyparsing (2.2.0)\n",
      "pytest (3.0.7)\n",
      "python-dateutil (2.6.1)\n",
      "pytz (2017.3)\n",
      "PyWavelets (0.5.2)\n",
      "PyYAML (3.12)\n",
      "pyzmq (16.0.2)\n",
      "QtAwesome (0.4.4)\n",
      "qtconsole (4.3.0)\n",
      "QtPy (1.2.1)\n",
      "regex (2017.7.28)\n",
      "requests (2.18.4)\n",
      "requests-file (1.4.2)\n",
      "requests-ftp (0.3.1)\n",
      "requests-oauthlib (0.8.0)\n",
      "rope-py3k (0.9.4.post1)\n",
      "scikit-image (0.13.0)\n",
      "scikit-learn (0.18.1)\n",
      "scipy (0.19.1)\n",
      "seaborn (0.7.1)\n",
      "setuptools (37.0.0)\n",
      "simplegeneric (0.8.1)\n",
      "singledispatch (3.4.0.3)\n",
      "six (1.11.0)\n",
      "smart-open (1.5.3)\n",
      "snowballstemmer (1.2.1)\n",
      "sortedcollections (0.5.3)\n",
      "sortedcontainers (1.5.7)\n",
      "spacy (1.9.0)\n",
      "Sphinx (1.5.6)\n",
      "spyder (3.1.4)\n",
      "SQLAlchemy (1.1.9)\n",
      "statsmodels (0.8.0)\n",
      "sympy (1.1)\n",
      "tables (3.3.0)\n",
      "tblib (1.3.2)\n",
      "tensorflow (1.4.0)\n",
      "tensorflow-tensorboard (0.4.0rc3)\n",
      "termcolor (1.1.0)\n",
      "terminado (0.6)\n",
      "testpath (0.3)\n",
      "tf-nightly (1.5.0.dev20171121)\n",
      "thinc (6.5.2)\n",
      "toolz (0.8.2)\n",
      "tornado (4.5.1)\n",
      "tqdm (4.15.0)\n",
      "traitlets (4.3.2)\n",
      "twython (3.5.0)\n",
      "ujson (1.35)\n",
      "unicodecsv (0.14.1)\n",
      "updates (0.1.7.1)\n",
      "urllib3 (1.22)\n",
      "wcwidth (0.1.7)\n",
      "webencodings (0.5.1)\n",
      "Werkzeug (0.12.2)\n",
      "wheel (0.30.0)\n",
      "widgetsnbextension (2.0.0)\n",
      "wrapt (1.10.11)\n",
      "xlrd (1.0.0)\n",
      "XlsxWriter (0.9.6)\n",
      "xlwings (0.10.4)\n",
      "xlwt (1.2.0)\n",
      "zict (0.1.2)\n",
      "zmq (0.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[16 19]\n",
      " [36 43]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[17 20]\n",
      " [37 44]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 0.43944669  0.03506458  0.30284667]\n",
      " [ 0.38108218  0.48891902  0.33775055]\n",
      " [ 0.57769668  0.55155587  0.40417099]\n",
      " [ 0.04021311  0.68273008  0.99437451]\n",
      " [ 0.32904625  0.6511935   0.8769691 ]], shape=(5, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Multiply 2 * 2 matrix\n",
    "# Multiply two 2x2 matrices\n",
    "x = tf.matmul([[1, 2],\n",
    "               [3, 4]],\n",
    "              [[4, 5],\n",
    "               [6, 7]])\n",
    "\n",
    "# Add one to each element\n",
    "# (tf.add supports broadcasting)\n",
    "#broadcasting: 퍼트리다의 의미, 크기가 작은 행렬을 크기가 큰 행렬로 맞추어 주는 기능, 축소는 데이터 손실 때문에 불가\n",
    "#아래와 같은 경우는 1이 [[1 1], [1 1]], shape(2,2)로 변환\n",
    "#차원이 다를 경우, expand_dims() 함수에 맞게 넣어야 함. \n",
    "#설명 참조: http://excelsior-cjh.tistory.com/entry/Matrix-Broadcasting-%ED%96%89%EB%A0%AC%EC%9D%98-%EB%B8%8C%EB%A1%9C%EB%93%9C%EC%BA%90%EC%8A%A4%ED%8C%85\n",
    "\n",
    "y = tf.add(x, 1)\n",
    "\n",
    "# Create a random random 5x3 matrix\n",
    "z = tf.random_uniform([5, 3])\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 3.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# Tensor object를 활용하여, tf.add, tf.subtract, tf.multiply로 활용도 가능하다.\n",
    "x = (tf.ones([1], dtype=tf.float32) + 1) * 2 - 1\n",
    "print(x)\n",
    "\n",
    "# Numpy를 활용하여 값을 변환하기\n",
    "import numpy as np\n",
    "\n",
    "x = tf.add(1, 1)                     # tf.Tensor with a value of 2\n",
    "y = tf.add(np.array(1), np.array(1)) # tf.Tensor with a value of 2\n",
    "z = np.multiply(x, y)                # numpy.int64 with a value of \n",
    "\n",
    "#반대로 tf.constant 활용하여 numpy -> tf로 변화\n",
    "np_x = np.array(2., dtype=np.float32)\n",
    "x = tf.constant(np_x)\n",
    "\n",
    "py_y = 3.\n",
    "y = tf.constant(py_y)\n",
    "\n",
    "z = x + y + 1\n",
    "print(z)\n",
    "print(z.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Print Tensorflow Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'x:0' shape=() dtype=float32, numpy=0.0>\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "0.0\n",
      "<bound method ResourceVariable.assign of <tf.Variable 'x:0' shape=() dtype=float32, numpy=42.0>>\n",
      "tf.Tensor(45.0, shape=(), dtype=float32)\n",
      "tf.Tensor(48.0, shape=(), dtype=float32)\n",
      "tf.Tensor([  45.   90.  180.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.get_variable(name=\"x\", shape=[], dtype=tf.float32, initializer=tf.zeros_initializer)\n",
    "print(x)\n",
    "\n",
    "#Tensorflow의 변수는 tensor로 나타냄으로, read_value()를 통해 현재 값으로 접근이 가능함.\n",
    "#Tensorflow의 함수는 자동으로 초기화\n",
    "print(x.read_value())\n",
    "\n",
    "#numpy를 통한 변환\n",
    "print(x.read_value().numpy())\n",
    "\n",
    "#Tensorflow변수의 값을 변경하기\n",
    "x.assign(42)\n",
    "print(x.assign)\n",
    "\n",
    "x.assign_add(3)\n",
    "print(x.read_value())\n",
    "\n",
    "#텐서 변수를 자유자제로 활용해보기\n",
    "print(x + 3)\n",
    "\n",
    "print(x * [1, 2, 4]) #자동으로 broadcasting해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Difference (Gradients)\n",
    "\n",
    " - tfe.gradients_function(f): 입력 f에 대해 arg 미분값을 돌려준다.\n",
    " - tfe.value_and_gradients_function(f): tfe.gradients_function(f)과 비슷하지만, 함수가 들어오면 이전 f값과 미분값에 대해 돌려줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "[<tf.Tensor: id=91, shape=(), dtype=float32, numpy=6.0>]\n",
      "2nd grad: (<tf.Tensor: id=100, shape=(), dtype=float32, numpy=6.0>, [<tf.Tensor: id=107, shape=(), dtype=float32, numpy=2.0>])\n",
      "[<tf.Tensor: id=132, shape=(), dtype=float32, numpy=2.0>]\n",
      "[<tf.Tensor: id=141, shape=(), dtype=float32, numpy=1.0>]\n",
      "[<tf.Tensor: id=151, shape=(), dtype=float32, numpy=-1.0>]\n"
     ]
    }
   ],
   "source": [
    "def square(x):\n",
    "    return tf.multiply(x, x)\n",
    "assert 9 == square(3.).numpy()\n",
    "\n",
    "grad = tfe.gradients_function(square)\n",
    "assert 6 == grad(3.)[0].numpy()\n",
    "\n",
    "print(square(3.))\n",
    "print(grad(3.)) #x^2 -> 2x -> 6\n",
    "\n",
    "#2차 gradients_function\n",
    "grad2 = tfe.value_and_gradients_function(lambda x: grad(x)[0])\n",
    "#assert 2 == grad2(3.)[0].numpy()\n",
    "print(\"2nd grad: {}\".format(grad2(3.)))\n",
    "\n",
    "#3차 grad.\n",
    "grad3 = tfe.gradients_function(lambda x: grad2(x)[0])\n",
    "#assert 0 == grad3(3.)[0].numpy()\n",
    "print(grad3(3.))\n",
    "\n",
    "#absolute value\n",
    "def abs(x):\n",
    "    return x if x > 0. else -x\n",
    "\n",
    "grad = tfe.gradients_function(abs)\n",
    "\n",
    "print(grad(2.0))  # [1.]\n",
    "print(grad(-2.0)) # [-1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 68.350456\n",
      "Loss at step 0: 65.718086\n",
      "Loss at step 20: 30.165155\n",
      "Loss at step 40: 14.152796\n",
      "Loss at step 60: 6.938043\n",
      "Loss at step 80: 3.685903\n",
      "Loss at step 100: 2.219365\n",
      "Loss at step 120: 1.557776\n",
      "Loss at step 140: 1.259202\n",
      "Loss at step 160: 1.124407\n",
      "Loss at step 180: 1.063529\n",
      "Final loss: 1.036945\n",
      "W, B = 3.057428, 2.128305\n"
     ]
    }
   ],
   "source": [
    "#실제 linear regression을 통하여 활용해보자\n",
    "\n",
    "def prediction(input, weight, bias):\n",
    "    return input * weight + bias\n",
    "\n",
    "# A toy dataset of points around 3 * x + 2\n",
    "NUM_EXAMPLES = 1000\n",
    "training_inputs = tf.random_normal([NUM_EXAMPLES])\n",
    "noise = tf.random_normal([NUM_EXAMPLES])\n",
    "training_outputs = training_inputs * 3 + 2 + noise\n",
    "\n",
    "# A loss function: Mean-squared error\n",
    "def loss(weight, bias):\n",
    "    error = prediction(training_inputs, weight, bias) - training_outputs\n",
    "    return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "# Function that returns the the derivative of loss with respect to\n",
    "# weight and bias\n",
    "grad = tfe.gradients_function(loss)\n",
    "\n",
    "# Train for 200 steps (starting from some random choice for W and B, on the same\n",
    "# batch of data).\n",
    "W = 5.\n",
    "B = 10.\n",
    "learning_rate = 0.01\n",
    "print(\"Initial loss: %f\" % loss(W, B).numpy())\n",
    "for i in range(200):\n",
    "    (dW, dB) = grad(W, B)\n",
    "    W -= dW * learning_rate\n",
    "    B -= dB * learning_rate\n",
    "    if i % 20 == 0:\n",
    "        print(\"Loss at step %d: %f\" % (i, loss(W, B).numpy()))\n",
    "print(\"Final loss: %f\" % loss(W, B).numpy())\n",
    "print(\"W, B = %f, %f\" % (W.numpy(), B.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Grad\n",
    "\n",
    "Custom Gradient 제작하기. \n",
    "\n",
    "주로 cross entropy나 log likelyhood에 쓰이는 예제로 log(1 + e^x) 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=115, shape=(), dtype=float32, numpy=0.5>]\n",
      "[<tf.Tensor: id=126, shape=(), dtype=float32, numpy=nan>]\n"
     ]
    }
   ],
   "source": [
    "def log1pexp(x):\n",
    "    return tf.log(1 + tf.exp(x))\n",
    "\n",
    "grad_log1pexp = tfe.gradients_function(log1pexp)\n",
    "\n",
    "print(grad_log1pexp(0.)) # [0.5]\n",
    "\n",
    "print(grad_log1pexp(100.)) # x = 100, nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=138, shape=(), dtype=float32, numpy=0.5>]\n",
      "[<tf.Tensor: id=150, shape=(), dtype=float32, numpy=1.0>]\n"
     ]
    }
   ],
   "source": [
    "@tfe.custom_gradient\n",
    "def log1pexp(x):\n",
    "    e = tf.exp(x)\n",
    "    def grad(dy):\n",
    "        return dy * (1 - 1 / (1 + e))\n",
    "    return tf.log(1 + e), grad\n",
    "grad_log1pexp = tfe.gradients_function(log1pexp)\n",
    "\n",
    "# Gradient at x = 0 works as before.\n",
    "print(grad_log1pexp(0.))\n",
    "# [0.5]\n",
    "# And now gradient computation at x=100 works as well.\n",
    "print(grad_log1pexp(100.))\n",
    "# [1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training models\n",
    "\n",
    " - eager에서는 특별히 수정해야 하지 않는 한, tf.layers와 같은 모듈을 사용을 권장함\n",
    " - Optimizer와 layer를 간단하게 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable & Optimization\n",
    "\n",
    " - tfe.Variable: 변형가능한 Tensor값을 저장하는 객체로써, 학습이나 미분을 할때 값에 대한 access가 가능함. 모델의 파라메터들이 python변수에 저장 될 수 있다는 이야기임\n",
    " - tfe.gradients_function(f): 쉬운 미분을 지원하지만, 모든 파라메터들이 f와 연동이 되어있어야 하여, 학습시 큰 파라메터에 대한 대응이 힘듬\n",
    " - tfe.implicit_gradients: 비슷한 기능이지만 몇가지 특수 기능이 있음?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 68.630684\n",
      "Loss at step 0: 65.957047\n",
      "Loss at step 20: 29.986712\n",
      "Loss at step 40: 13.927011\n",
      "Loss at step 60: 6.756695\n",
      "Loss at step 80: 3.555240\n",
      "Loss at step 100: 2.125806\n",
      "Loss at step 120: 1.487559\n",
      "Loss at step 140: 1.202574\n",
      "Loss at step 160: 1.075323\n",
      "Loss at step 180: 1.018501\n",
      "Loss at step 200: 0.993129\n",
      "Final loss: 0.993129\n",
      "W, B = 3.02484, 2.1537\n"
     ]
    }
   ],
   "source": [
    "#실제 linear regression을 통하여 활용해보자\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self):\n",
    "        self.W = tfe.Variable(5., name='weight')\n",
    "        self.B = tfe.Variable(10., name='bias')\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        return inputs * self.W + self.B\n",
    "\n",
    "\n",
    "# The loss function to be optimized\n",
    "def loss(model, inputs, targets):\n",
    "    error = model.predict(inputs) - targets\n",
    "    return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "# A toy dataset of points around 3 * x + 2\n",
    "NUM_EXAMPLES = 1000\n",
    "training_inputs = tf.random_normal([NUM_EXAMPLES])\n",
    "noise = tf.random_normal([NUM_EXAMPLES])\n",
    "training_outputs = training_inputs * 3 + 2 + noise\n",
    "\n",
    "# Define:\n",
    "# 1. A model\n",
    "# 2. Derivatives of a loss function with respect to model parameters\n",
    "# 3. A strategy for updating the variables based on the derivatives\n",
    "model = Model()\n",
    "grad = tfe.implicit_gradients(loss)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "# The training loop\n",
    "print(\"Initial loss: %f\" %\n",
    "      loss(model, training_inputs, training_outputs).numpy())\n",
    "for i in range(201):\n",
    "    optimizer.apply_gradients(grad(model, training_inputs, training_outputs))\n",
    "    if i % 20 == 0:\n",
    "        print(\"Loss at step %d: %f\" %\n",
    "              (i, loss(model, training_inputs, training_outputs).numpy()))\n",
    "print(\"Final loss: %f\" % loss(model, training_inputs, training_outputs).numpy())\n",
    "print(\"W, B = %s, %s\" % (model.W.numpy(), model.B.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models (개선필요)\n",
    "\n",
    "MNIST 2 Layer모델을 간단하게 Class로 만드는 예제\n",
    "\n",
    "tfe.Network: 기본적으로 layer의 Container역할을 하여, 다른 NW객체에 임비디드 되어 NW객체가 된다.\n",
    "\n",
    "추가로, inspection, saving, & restoring에 도움을 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNISTModel(tfe.Network):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.layer1 = self.track_layer(tf.layers.Dense(units=10))\n",
    "        self.layer2 = self.track_layer(tf.layers.Dense(units=10))\n",
    "    def call(self, input):\n",
    "        \"\"\"모델 실행\"\"\"\n",
    "        result = self.layer1(input)\n",
    "        result = self.layer2(result)\n",
    "        return result\n",
    "    \n",
    "#placeholder나 session에 대한 기능이 없고, input을 pass되면 자동으로 세팅 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 784)\n",
      "tf.Tensor([[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]], shape=(1, 1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋 생성하기\n",
    "model = MNISTModel()\n",
    "batch = tf.zeros([1, 1, 784])\n",
    "print(batch.shape)\n",
    "result = model(batch)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EagerTensor' object has no attribute '_as_variant_tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5afbcb6c178e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimplicit_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_nightly/lib/python3.6/site-packages/tensorflow/contrib/eager/python/datasets.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     75\u001b[0m           format(type(self)))\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/device:CPU:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       \u001b[0mds_variant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_variant_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EagerTensor' object has no attribute '_as_variant_tensor'"
     ]
    }
   ],
   "source": [
    "#학습을 위한 loss func, grad, 그리고 업데이트\n",
    "\n",
    "#1. loss func\n",
    "def loss_function(model, x, y):\n",
    "    y_ = model(x)\n",
    "    return tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_)\n",
    "\n",
    "#2. training loop\n",
    "#implicit_gradients(): 모든 TF 값에 대한 미분을 계산한다.\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate =0.001)\n",
    "for (x, y) in tfe.Iterator(dataset):\n",
    "    grads = tfe.implicit_gradients(loss_function)(model, x, y)\n",
    "    optimizer.apply_gradients(grads)\n",
    "\n",
    "#GPU사용하기\n",
    "#optimizer.min을 통해서, 짧게 작성하였지만, apply_gradients()기능을 써도 가능\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    for (x, y) in tfe.Iterator(dataset):\n",
    "        optimizer.minimize(lambda: loss_function(model, x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU 사용하기\n",
    "\n",
    " - eager에서는 GPU가 자동으로 실행되지 않기 때문에, 지정해주고 사용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: Took 0.26638007164001465 seconds to multiply a (1000, 1000) matrix by itself 10 times\n"
     ]
    }
   ],
   "source": [
    "#1000*1000 매트릭스 계산하기\n",
    "\n",
    "import time\n",
    "\n",
    "def measure(x):\n",
    "    # The very first time a GPU is used by TensorFlow, it is initialized.\n",
    "    # So exclude the first run from timing.\n",
    "    tf.matmul(x, x)\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(10):\n",
    "        tf.matmul(x, x)\n",
    "    end = time.time()\n",
    "\n",
    "    return \"Took %s seconds to multiply a %s matrix by itself 10 times\" % (end - start, x.shape)\n",
    "\n",
    "# Run on CPU:\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    print(\"CPU: %s\" % measure(tf.random_normal([1000, 1000])))\n",
    "\n",
    "# If a GPU is available, run on GPU:\n",
    "if tfe.num_gpus() > 0:\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        print(\"GPU: %s\" % measure(tf.random_normal([1000, 1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error copying tensor to device: GPU:0. GPU:0 unknown device.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-76e20da2e730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx_gpu0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mx_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_nightly/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mgpu\u001b[0;34m(self, gpu_index)\u001b[0m\n\u001b[1;32m    756\u001b[0m       \u001b[0;32mas\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \"\"\"\n\u001b[0;32m--> 758\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"GPU:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_nightly/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_copy\u001b[0;34m(self, ctx, device_name)\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m       \u001b[0mnew_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error copying tensor to device: GPU:0. GPU:0 unknown device."
     ]
    }
   ],
   "source": [
    "#Tensor 객체를 활용하여, 각 디바이스 별로 활용하는 것이 가능하다\n",
    "\n",
    "x = tf.random_normal([10, 10])\n",
    "\n",
    "x_gpu0 = x.gpu()\n",
    "x_cpu = x.cpu()\n",
    "\n",
    "_ = tf.matmul(x_cpu, x_cpu)  # Runs on CPU\n",
    "_ = tf.matmul(x_gpu0, x_gpu0)  # Runs on GPU:0\n",
    "\n",
    "if tfe.num_gpus() > 1:\n",
    "    x_gpu1 = x.gpu(1)\n",
    "    _ = tf.matmul(x_gpu1, x_gpu1)  # Runs on GPU:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Eagar with Graphs\n",
    "\n",
    "- Eagar 자체는 개발하고 디버깅 할 때 좋은 기능을 가지지만, Tensorflow graph형식이 분산 학습, 성능 최적화, 상용개발에 더 적합\n",
    "- 현재 모델을 graph형태로 변경하기 위해서는, eager를 disable하고 실행하면 됨\n",
    "- 관련 예제 코드: [MNIST with Eager](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/mnist)\n",
    "- 위의 예제 코드는 checkpoints를 저장하고 불러올 수 있기 때문에, 상용에도 적합하다.\n",
    "\n",
    "## 현재 활용하고 있는 코드의 변화\n",
    " \n",
    "- 현재 사용하고 있는 데이터에서, 형태를 tf.data로 변경하는것을 추천 드립니다.\n",
    "  - [참고링크 1](https://developers.googleblog.com/2017/09/introducing-tensorflow-datasets.html)\n",
    "  - [참고링크 2](https://www.tensorflow.org/programmers_guide/datasets)\n",
    "- tf.layer.Conv2D()와 같은 Object-oriented 기능 활용을 추천 (Explict storage for variables\n",
    "- 대부분의 모델이 eagar로 활용이 가능하지만, dynamic 모델에 대한 control flow같은 경우는 추가로 검토가 필요\n",
    "- tfe.enable_eagar_execution()을 활용하면, 끌수가 없기 때문에 Python 세션을 재시작 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
